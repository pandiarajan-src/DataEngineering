{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Challenges\n",
    "\n",
    "1. Read in JSON data and write to Parquet format\n",
    "2. Join two datasets then perform group_by aggregation\n",
    "3. Select subset of columns, filter rows, and add new column\n",
    "4. Build expression to find correlations between columns\n",
    "5. Use Polars for analysis that exceeds Pandas capabilities\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of a polar \n",
    "\n",
    "import polars as pl\n",
    "\n",
    "# Create DataFrame \n",
    "data = [{\"fruit\": \"apple\", \"count\": 10, \"price\": 0.50}, \n",
    "        {\"fruit\": \"banana\", \"count\": 20, \"price\": 0.25}]\n",
    "df = pl.from_dicts(data)\n",
    "\n",
    "# Expressions to select, filter, aggregate\n",
    "sel = df.select([\"fruit\", \"count\"]) # Select columns\n",
    "filt = sel.filter(pl.col(\"fruit\") == \"apple\") # Filter rows\n",
    "agg = filt.group_by(\"fruit\").agg(pl.col(\"count\").sum()) # Aggregate\n",
    "\n",
    "print(agg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a JSON data\n",
    "import ipynb.fs.full.Create_data_helper as cdh\n",
    "\n",
    "# Create a CSV and JSON file for storing weather data\n",
    "cdh.create_random_weather_data(\"weather_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Read in JSON data and write to Parquet format\n",
    "\n",
    "import polars as pl\n",
    "\n",
    "weather_data = pl.read_json(\"weather_data.json\")\n",
    "weather_data.write_parquet(\"weather_data.parquet\")\n",
    "weather_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "\n",
    "# read weather JSON data into polars DataFrame\n",
    "df = pl.read_json(\"weather_data.json\")\n",
    "\n",
    "# Create data set1 that filter rows based on condition\n",
    "max_temp = df.filter(pl.col(\"Temperature\") > pl.col(\"Temperature\").mean())\n",
    "print(max_temp)\n",
    "\n",
    "# Create data set2 that filter rows based on condition\n",
    "sunny = df.filter(pl.col(\"Weather Condition\") == \"sunny\")\n",
    "print(sunny)\n",
    "\n",
    "# 2. Join two datasets then perform group_by aggregation\n",
    "jd = max_temp.join(sunny, on=\"Temperature\", how=\"inner\")\n",
    "print(jd)\n",
    "\n",
    "agg = jd.group_by(\"Weather Condition\").agg(pl.col(\"Temperature\"))\n",
    "print(agg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "\n",
    "# read weather JSON data into polars DataFrame\n",
    "df = pl.read_json(\"weather_data.json\")\n",
    "\n",
    "# 3. Select subset of columns, filter rows, and add new column\n",
    "df1 = df.select([\"Temperature\", \"Humidity\"]).filter(pl.col(\"Temperature\") > pl.col(\"Temperature\").mean())\n",
    "df1 = df1.rename({\"Temperature\": \"Tempeature_in_C\"})\n",
    "df2 = df1.with_columns(Tempeature_in_F = ((pl.col(\"Tempeature_in_C\") * 1.8) + 32))\n",
    "\n",
    "print(df1)\n",
    "print(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Build expression to find correlations between columns\n",
    "\n",
    "import polars as pl\n",
    "\n",
    "df = pl.read_json(\"weather_data.json\")\n",
    "\n",
    "corr = df.select(pl.corr(\"Temperature\", \"Humidity\"))\n",
    "print(corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "\n",
    "# Sample DataFrame\n",
    "data = {\"col1\": [1, 2, 3, 4, 5], \"col2\": [2, 4, 5, 4, 5]}\n",
    "df = pl.DataFrame(data)\n",
    "\n",
    "# Calculate Pearson correlation\n",
    "correlation = df.select(pl.corr(\"col1\", \"col2\", method=\"pearson\"))\n",
    "print(correlation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dee_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
